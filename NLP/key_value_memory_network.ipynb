{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhZzhjGaTj9P"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This project, based on **OMSCS7650 Natural Language Processing**, explores the attention mechanism in a **question-answering (QA) task**, comparing **multihot** and **GloVe** implementations using a **Key-Value Memory Network (KVMemNet)**.\n",
        "\n",
        "Unlike traditional Knowledge Bases, KVMemNet learns to access an external memory store—organized as keys and values—without encoding all information directly into the model parameters, allowing updates without retraining.\n",
        "Given a question, the model computes similarity between the question and memory keys, applies an attention-scoring mechanism to select relevant keys, and uses the corresponding values to predict the answer. This single-hop design supports end-to-end learning and illustrates self-attention concepts without the full complexity of transformers."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Disclaimer\n",
        "\n",
        "The code preceding Step 2 is adapted and modified from **OMSCS7650: Natural Language Processing**."
      ],
      "metadata": {
        "id": "qCK9KPN4cqUs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLQP14bxNXDx"
      },
      "source": [
        "# Libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfnqkHKkITC3",
        "outputId": "23b32aeb-6c86-4a25-d7bb-9adbbbb42245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode\n",
        "import unidecode\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import re\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "from math import ceil\n",
        "import time\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "'''\n",
        "The file private_models contains KVMemNet model implementations used in this project.\n",
        "\n",
        "For academic integrity, it is not included in this repository because the course\n",
        "OMSCS 7650: Natural Language Processing may still use this topic for assignments.\n",
        "\n",
        "Upon request for demonstration for employment or other legitimate purposes,\n",
        "the author may provide it privately.\n",
        "'''\n",
        "\n",
        "from private_models import PrivateModels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AviW7dfn6pUi",
        "outputId": "ce835341-b6d4-4c67-c4c2-3564aad3e6ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl6J8BwVpHCw"
      },
      "source": [
        "# Pre-process Functions on Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CPwG_8VrNUop"
      },
      "outputs": [],
      "source": [
        "# Stemming\n",
        "def simple_stemmer(text):\n",
        "    ps=nltk.porter.PorterStemmer()\n",
        "    text= [ps.stem(word) for word in text]\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eEofSDrQ9fg_"
      },
      "outputs": [],
      "source": [
        "# Tokenization (keep letters and numbers)\n",
        "def tokenize(line):\n",
        "    line = re.sub(r'[^a-zA-Z0-9]', ' ', unidecode.unidecode(line))\n",
        "    line = line.lower().split()\n",
        "    return line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "25siAXsXOJj9"
      },
      "outputs": [],
      "source": [
        "# Standard vocabulary object class\n",
        "class Vocab:\n",
        "    def __init__(self, name = 'vocab'):\n",
        "        self.name = name\n",
        "        self._word2index = {}\n",
        "        self._word2count = {}\n",
        "        self._index2word = {}\n",
        "        self._n_words = 0\n",
        "        self.add_word(UNK)\n",
        "\n",
        "    def get_words(self):\n",
        "      return list(self._word2count.keys())\n",
        "\n",
        "    def num_words(self):\n",
        "      return self._n_words\n",
        "\n",
        "    def word2index(self, word):\n",
        "      return self._word2index.get(word, UNK_ID)\n",
        "\n",
        "    def index2word(self, index):\n",
        "      return self._index2word.get(index, UNK)\n",
        "\n",
        "    def word2count(self, word):\n",
        "      return self._word2count.get(word, 0)\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in tokenize(sentence):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self._word2index:\n",
        "            self._word2index[word] = self._n_words\n",
        "            self._word2count[word] = 1\n",
        "            self._index2word[self._n_words] = word\n",
        "            self._n_words += 1\n",
        "        else:\n",
        "            self._word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oKJP2y8g-TFE"
      },
      "outputs": [],
      "source": [
        "# Multihot: Make a bag of words from a sentence (s), given a vocabulary (vocab)\n",
        "# Either return a bag of word counts or a bag of word presences.\n",
        "def multihot(s, vocab, preserve_counts = False):\n",
        "  tokens = np.array([vocab.word2index(t) for t in tokenize(s)])\n",
        "  mhot = np.zeros((tokens.size, vocab.num_words()))\n",
        "  mhot[np.arange(tokens.size), tokens] = 1\n",
        "  if preserve_counts:\n",
        "    return mhot.sum(0)\n",
        "  else:\n",
        "    return mhot.sum(0) >= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4Edhwwcg6s42"
      },
      "outputs": [],
      "source": [
        "# For vocabulary, create an unknown \"unk\" token with token index in the vocabulary (UNK_ID).\n",
        "UNK = 'unk'\n",
        "UNK_ID = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHZm-bAanrrf"
      },
      "source": [
        "# Step 1: Download & Process Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-L61V7tVPok"
      },
      "source": [
        "Data link: https://github.com/DavidGrangier/wikipedia-biography-dataset\n",
        "\n",
        "The raw data contains the information in tables that are commonly used in Wikipedia biography pages. Each entity (i.e., each person) has different rows of information and details.\n",
        "\n",
        "For example, [Alexander Hamilton](https://en.wikipedia.org/wiki/Alexander_Hamilton) has information about birth date, death date, spouse, political party, etc, which are the **keys**. The value of a key like **birth date** is the specific value like **11 january 1755**. **keys** are also called **relations** in this project.\n",
        "\n",
        "After pre-processing, two things are created from the raw data:\n",
        "- **`DB`**: a hash table that map titles of biography wikipedia articles to table information. The table information is represented as a nested hash table containing relations as keys, and associated values. For example, \\\n",
        "`DB['alexander hamilton'] = {'birth_date': '11 january 1755','party': 'federalist', ...}`\n",
        "\n",
        "- **`VOCAB`**: A vocabulary object that maps words to tokens and vice versa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYzcdAR2ntvm",
        "outputId": "0a92ca89-0426-496a-eefa-0ce0f92fbcba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'wikipedia-biography-dataset'...\n",
            "remote: Enumerating objects: 93, done.\u001b[K\n",
            "remote: Total 93 (delta 0), reused 0 (delta 0), pack-reused 93 (from 1)\u001b[K\n",
            "Receiving objects: 100% (93/93), 338.68 MiB | 25.98 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n",
            "Updating files: 100% (19/19), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rlebret/wikipedia-biography-dataset.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZEHbtftn17L",
        "outputId": "0d086325-f38a-4bcd-b3ac-5eef674d0069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  tmp.zip\n",
            "   creating: wikipedia-biography-dataset/test/\n",
            "  inflating: wikipedia-biography-dataset/test/test.box  \n",
            "  inflating: wikipedia-biography-dataset/test/test.id  \n",
            "  inflating: wikipedia-biography-dataset/test/test.nb  \n",
            "  inflating: wikipedia-biography-dataset/test/test.sent  \n",
            "  inflating: wikipedia-biography-dataset/test/test.url  \n",
            "  inflating: wikipedia-biography-dataset/test/test.contributors  \n",
            "  inflating: wikipedia-biography-dataset/test/test.title  \n",
            "   creating: wikipedia-biography-dataset/train/\n",
            "  inflating: wikipedia-biography-dataset/train/train.box  \n",
            "  inflating: wikipedia-biography-dataset/train/train.id  \n",
            "  inflating: wikipedia-biography-dataset/train/train.nb  \n",
            "  inflating: wikipedia-biography-dataset/train/train.sent  \n",
            "  inflating: wikipedia-biography-dataset/train/train.url  \n",
            "  inflating: wikipedia-biography-dataset/train/train.contributors  \n",
            "  inflating: wikipedia-biography-dataset/train/train.title  \n",
            "   creating: wikipedia-biography-dataset/valid/\n",
            "  inflating: wikipedia-biography-dataset/valid/valid.box  \n",
            "  inflating: wikipedia-biography-dataset/valid/valid.id  \n",
            "  inflating: wikipedia-biography-dataset/valid/valid.nb  \n",
            "  inflating: wikipedia-biography-dataset/valid/valid.sent  \n",
            "  inflating: wikipedia-biography-dataset/valid/valid.url  \n",
            "  inflating: wikipedia-biography-dataset/valid/valid.contributors  \n",
            "  inflating: wikipedia-biography-dataset/valid/valid.title  \n",
            "  inflating: wikipedia-biography-dataset/LICENSE.txt  \n",
            "  inflating: wikipedia-biography-dataset/.DS_Store  \n",
            "  inflating: wikipedia-biography-dataset/._.DS_Store  \n",
            "  inflating: wikipedia-biography-dataset/README.txt  \n"
          ]
        }
      ],
      "source": [
        "# Decompressing zip files\n",
        "!cat wikipedia-biography-dataset/wikipedia-biography-dataset.z?? > tmp.zip\n",
        "!unzip -o tmp.zip\n",
        "!rm tmp.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zhdWH8jnBbJg"
      },
      "outputs": [],
      "source": [
        "# Clean titles\n",
        "def clean_title(title):\n",
        "    title = re.sub(r'-lrb-.*?-rrb-', '', title, flags=re.IGNORECASE)\n",
        "    title = re.sub(r'\\s+([,.])', r'\\1', title)  # Remove space before punctuation\n",
        "    title = re.sub(r'\\.\\s*\\.', '.', title)      # Replace \". .\" with \".\"\n",
        "    title = re.sub(r'\\s+', ' ', title)          # Normalize spaces\n",
        "\n",
        "    # Keep only the part before the first comma\n",
        "    if ',' in title:\n",
        "        title = title.split(',')[0].strip()\n",
        "\n",
        "    return title\n",
        "\n",
        "# Get wikipedia titles (cleaned)\n",
        "train_titles = []\n",
        "with open(\"wikipedia-biography-dataset/train/train.title\", \"r\") as file:\n",
        "    for line in file:\n",
        "        cleaned = clean_title(line.rstrip())\n",
        "        train_titles.append(cleaned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "C80pu63x4o-Y"
      },
      "outputs": [],
      "source": [
        "# Get boxes, which contain all the information - each line corresponds to a wikipedia title.\n",
        "train_boxes = []\n",
        "with open(\"wikipedia-biography-dataset/train/train.box\", \"r\") as file:\n",
        "  for line in file:\n",
        "    train_boxes.append(line.rstrip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Pr97KJLc4v7v"
      },
      "outputs": [],
      "source": [
        "# Only keeps the entities containing \"office\" key term\n",
        "# Make a dictionary of dictionaries\n",
        "def make_db(titles, boxes):\n",
        "  db = {} # The DB\n",
        "  # Iterate through titles\n",
        "  for i in tqdm(range(len(titles))):\n",
        "    box = boxes[i] # Grab the corresponding box information\n",
        "    d  = {} # Inner dictionary\n",
        "    # Build a dict for the ith entry\n",
        "    # grab each key:value pair\n",
        "    for pair in re.findall(r'([a-zA-Z_]+)[0-9]*\\:([\\w\\d]+)', box):\n",
        "      key, value = pair\n",
        "      # Do a bit of cleaning\n",
        "      key = key.strip()\n",
        "      value = value.strip()\n",
        "      # If the key contains the word image, we probably don't want to keep it\n",
        "      if 'image' not in key:\n",
        "        # The regex maintains underscores, strip those off\n",
        "        if key[-1] == '_':\n",
        "          key = key[:-1]\n",
        "        # Make a new entry in inner dictionary if we don't have one\n",
        "        if key not in d:\n",
        "          d[key] = value\n",
        "        # Keys with compound values are split up, which is annoying, so put them back together\n",
        "        else:\n",
        "          d[key] += ' ' + value\n",
        "    # If it has an office key, keep it.\n",
        "    if 'office' in d:\n",
        "      db[titles[i]] = d\n",
        "  return db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "p13O5dcVvdZu"
      },
      "outputs": [],
      "source": [
        "# Build vocab from DB\n",
        "def make_vocab(DB):\n",
        "  # Make the vocab object\n",
        "  vocab = Vocab()\n",
        "  # Tokenize the data by converting the entire DB into a string\n",
        "  tokens = tokenize(str(DB))\n",
        "  # Iterate through all the tokens (tqdm provides a progress bar)\n",
        "  for t in tqdm(tokens):\n",
        "    vocab.add_word(t)\n",
        "  return vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "448Ww-BFtBL3"
      },
      "outputs": [],
      "source": [
        "# Reduce vocabulary by discarding rare words\n",
        "def reduce_vocab(vocab, min_word_occurrence):\n",
        "  # make a new vocab\n",
        "  vocab2 = Vocab(\"top\")\n",
        "  # Add the UNK token\n",
        "  vocab2.add_word(UNK)\n",
        "  # Iterate through vocabulary\n",
        "  for w in list(vocab._word2count.keys()):\n",
        "    count = vocab._word2count[w]\n",
        "    idx = vocab._word2index[w]\n",
        "    # If the word count passes threshold, add it to the new vocabulary object\n",
        "    if count >= min_word_occurrence:\n",
        "      vocab2.add_word(w)\n",
        "      vocab2._word2count[w] = count\n",
        "  # Return the new vocabulary object\n",
        "  return vocab2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cio_ZwncrGf0",
        "outputId": "bfa06f7a-4fd8-4a45-b651-fd1a53893cfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 582659/582659 [00:56<00:00, 10235.68it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40520"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Create DB\n",
        "DB = make_db(train_titles, train_boxes)\n",
        "len(DB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc7oi3p54SOb",
        "outputId": "c7cadc90-b81a-4201-dd8d-d0d0eb08b465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2961869/2961869 [00:01<00:00, 1946947.74it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95897"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Create VOCAB\n",
        "VOCAB = make_vocab(DB)\n",
        "VOCAB.num_words()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnUnFb6Dn5lW",
        "outputId": "39392ce9-e12e-4c81-e57a-cdf5e79c66f1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6DNxueU-gpz_"
      },
      "outputs": [],
      "source": [
        "# Save DB & VOCAB to drive\n",
        "with open(\"drive/MyDrive/NLP/DB\", \"wb\") as f:\n",
        "  pickle.dump(DB, f, protocol=None, fix_imports=True, buffer_callback=None)\n",
        "\n",
        "with open('drive/MyDrive/NLP/VOCAB', 'wb') as f:\n",
        "    pickle.dump(VOCAB, f, protocol=None, fix_imports=True, buffer_callback=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZCaiBhdvCa_C"
      },
      "outputs": [],
      "source": [
        "# Load DB & VOCAB\n",
        "with open(\"drive/MyDrive/NLP/DB\", \"rb\") as f:\n",
        "  DB = pickle.load(f)\n",
        "\n",
        "with open(\"drive/MyDrive/NLP/VOCAB\", \"rb\") as f:\n",
        "  VOCAB = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbLkOyB2pp_M",
        "outputId": "478f3b6a-8bff-4c1b-9584-f02cf0cfd3d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'chris watson',\n",
              " 'order': '3rd prime minister of australia elections 1903 1906',\n",
              " 'term_start': '27 april 1904 27 april 1904 20 may 1901 18 august 1904 8 november 1906 30 march 1901',\n",
              " 'term_end': '18 august 1904 17 august 1904 30 october 1907 5 july 1905 13 april 1910 12 december 1906',\n",
              " 'monarch': 'edward vii',\n",
              " 'predecessor': 'alfred deakin sir george turner george reid george edwards constituency created',\n",
              " 'successor': 'george reid sir george turner andrew fisher george reid edward riley constituency abolished',\n",
              " 'office': 'treasurer of australia 1st leader of the labor party leader of the opposition member of the australian parliament for south sydney member of the australian parliament for bland',\n",
              " 'primeminister': 'chris watson',\n",
              " 'deputy': 'gregor mcgregor',\n",
              " 'birth_name': 'john christian tanck',\n",
              " 'birth_date': 'c 9 april 1867',\n",
              " 'birth_place': 'valparaíso chile',\n",
              " 'death_date': '18 november 1941',\n",
              " 'death_place': 'sydney new south wales australia',\n",
              " 'party': 'australian labour party',\n",
              " 'spouse': 'ada watson died 1921 antonia mary gladys watson married 1925 aged 23',\n",
              " 'children': 'jacqueline born 1925',\n",
              " 'religion': 'unitarianism',\n",
              " 'article_title': 'chris watson'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Examine the entry in DB\n",
        "DB['chris watson']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITACHJTWfE5m"
      },
      "source": [
        "# Step 2: Build Key-Value Memory Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQqLE-fcI_43"
      },
      "source": [
        "**Question Answering (QA)** systems have traditionally relied on structured **Knowledge Bases (KBs)** like Freebase to retrieve answers, as their schema-driven organization makes logical queries tractable.\n",
        "\n",
        "However, KBs are inherently incomplete and rigid to handle the richness and diversity of information found in natural text sources like Wikipedia. As a result, there's growing interest in designing models capable of reading unstructured documents directly and answering questions from them.\n",
        "\n",
        "\n",
        "To tackle this challenge, the **Key-Value Memory Network (KVMemNet) model** was introduced. It enhances the original Memory Network by separating the addressing and reading phases using distinct **key-value representations**. In this architecture, both the question and memory slots (facts) are represented as bag-of-words and embedded into a shared vector space. Keys help match the question to relevant memory slots, while values provide the corresponding answer representations.\n",
        "\n",
        "The KVMemNet performs a soft attention mechanism over the keys to compute relevance scores, then uses these scores to produce a weighted sum of the values—yielding a final feature vector that leads to the predicted answer. Unlike rigid KB queries, this approach supports neural reasoning over text, enabling end-to-end learning with standard backpropagation. It also generalizes to multi-hop reasoning, where the model refines its internal query vector through repeated attention rounds.\n",
        "\n",
        "This project focuses on implementing a single-hop version of KVMemNet, where a question is matched to the best key, and the corresponding value is used to form the prediction. The design is well-suited for tasks where symbolic queries over structured KBs are not feasible, and the goal is to extract information from raw, potentially noisy, textual inputs.\n",
        "\n",
        "Key-value memory networks are described in this [paper](https://arxiv.org/abs/1606.03126)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "KVMemNet model is defined in private_models.PrivateModels for this project.\n",
        "The implementation is hidden for academic integrity.\n",
        "'''\n",
        "KVMemNet = PrivateModels.KVMemNet"
      ],
      "metadata": {
        "id": "ejgju6h67pHs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nupd-Gr9P6vc"
      },
      "source": [
        "# Step 3: Training and Testing Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho_WoQJqPjYK",
        "outputId": "7a7c304e-10f3-4599-fe3f-1cab6111638e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 15 most common relation-frequency pairs:\n",
            "office: 40520\n",
            "article_title: 40520\n",
            "term_start: 36895\n",
            "birth_date: 35032\n",
            "birth_place: 31965\n",
            "term_end: 30915\n",
            "predecessor: 29415\n",
            "party: 28195\n",
            "successor: 25939\n",
            "alma_mater: 16212\n",
            "death_date: 15185\n",
            "spouse: 14961\n",
            "death_place: 12457\n",
            "nationality: 10715\n",
            "religion: 10475\n"
          ]
        }
      ],
      "source": [
        "# Examine the top-k most frequent relations in DB\n",
        "\n",
        "k = 15\n",
        "\n",
        "# Count all relation frequencies (excluding 'name')\n",
        "relation_cnt = Counter()\n",
        "for entry in DB.values():\n",
        "    relation_cnt.update(relation for relation in entry if relation != 'name')\n",
        "\n",
        "# Get top-k relation_frequency pair\n",
        "top_k_relation_freq = relation_cnt.most_common(k)\n",
        "\n",
        "print(f\"Top {k} most common relation-frequency pairs:\")\n",
        "for relation, frequency in top_k_relation_freq:\n",
        "    print(f\"{relation}: {frequency}\")\n",
        "\n",
        "#top_k_relations = set(relation for relation, frequency in top_k_relation_freq)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: To accommodate computational resource constraints, the training and testing datasets in this project have been trimmed and simplified. Specifically, only three of the top 15 most frequent keys are selected, and a total of 600 entities are used for training and evaluation."
      ],
      "metadata": {
        "id": "LnC6g8Vv8tRp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6VEnB_VS7Px",
        "outputId": "e0261263-00e9-44c3-b64d-fea3316154ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entities (people) in trimmed_DB: 36338\n"
          ]
        }
      ],
      "source": [
        "# Create training and testing datasets\n",
        "select_keys = {'birth_date', 'death_date' , 'religion'}\n",
        "trimmed_DB = []\n",
        "name_to_index = {}\n",
        "name_list = []\n",
        "\n",
        "for name, content in DB.items():\n",
        "    person = []\n",
        "    for key, value in content.items():\n",
        "        if key in select_keys:\n",
        "            question = f\"{name} {key}\"              # question, or key\n",
        "            answer = f\"{name} {value}\"              # answer, or value\n",
        "            person.append([name, question, answer])\n",
        "    if person:\n",
        "        name_list.append(name)\n",
        "        name_to_index[name] = len(trimmed_DB)\n",
        "        trimmed_DB.append(person)\n",
        "\n",
        "print(f\"Number of entities (people) in trimmed_DB: {len(trimmed_DB)}\")\n",
        "\n",
        "train_data = trimmed_DB[:500]\n",
        "test_data = trimmed_DB[500:600]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx_NelGqfZBx",
        "outputId": "9064f9be-a4e8-4df5-9cbd-3371f4125e53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 714238/714238 [00:00<00:00, 924264.68it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of words in trimmed_VOCAB: 31558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Build trimmed_VOCAB based on trimmed_DB\n",
        "trimmed_VOCAB = make_vocab(trimmed_DB)\n",
        "print()\n",
        "print(f\"Number of words in trimmed_VOCAB: {trimmed_VOCAB.num_words()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf78cNoXfiuM",
        "outputId": "df6bd353-9894-406b-8c48-6d0ea963b5b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in reduced_VOCAB: 20069\n"
          ]
        }
      ],
      "source": [
        "# Further reduce trimmed_VOCAB by removing rare words\n",
        "reduced_VOCAB = reduce_vocab(trimmed_VOCAB, min_word_occurrence=5)\n",
        "print(f\"Number of words in reduced_VOCAB: {reduced_VOCAB.num_words()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Apply Key-Value Memory Network on Data (DB) - Multihot"
      ],
      "metadata": {
        "id": "dNpKWjjk2GZM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI3b5x2zfl8g"
      },
      "source": [
        "**Setup `KVMemNet`, Training, Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "OEKJ1KJxTBUJ"
      },
      "outputs": [],
      "source": [
        "# Set up Key-Value Memory Network\n",
        "vocab_size = reduced_VOCAB.num_words()\n",
        "embed_size = 128\n",
        "learning_rate = 0.01\n",
        "num_epochs = 15\n",
        "\n",
        "model = KVMemNet(vocab_size=vocab_size, embed_dim=embed_size).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "RfGSuAbMossa"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "def train_KVMemNet(model, optimizer, criterion, train_data, num_epochs, device):\n",
        "    model.train()\n",
        "\n",
        "    epoch_losses = []\n",
        "    epoch_accuracies = []\n",
        "    epoch_times = []\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "        losses = []\n",
        "        correct_pred = 0\n",
        "        total_sample = 0\n",
        "        random.seed(epoch)\n",
        "\n",
        "        for people_index in range(len(train_data)):\n",
        "            batch_data = train_data[people_index]\n",
        "\n",
        "            # Add random data\n",
        "            random_person_1 = train_data[random.randint(0, len(train_data)-1)]\n",
        "            random_person_2 = train_data[random.randint(0, len(train_data)-1)]\n",
        "            concatenate = batch_data + random_person_1 + random_person_2\n",
        "\n",
        "            keys = [multihot(item[1], reduced_VOCAB) for item in concatenate]\n",
        "            values = [multihot(item[2], reduced_VOCAB) for item in concatenate]\n",
        "\n",
        "            keys = torch.stack([torch.tensor(k, dtype=torch.float32) for k in keys]).unsqueeze(0).to(device)\n",
        "            values = torch.stack([torch.tensor(v, dtype=torch.float32) for v in values]).unsqueeze(0).to(device)\n",
        "\n",
        "            y_embed = model.embedding_B(values.clone()).squeeze(0).detach()\n",
        "\n",
        "            for relation_index in range(len(batch_data)):\n",
        "                question = keys[0][relation_index].unsqueeze(0).to(device)\n",
        "\n",
        "                output = model(question, keys, values).squeeze(0)\n",
        "                attention_score = torch.nn.functional.softmax(torch.inner(y_embed, output), dim=0)\n",
        "\n",
        "                target_index = relation_index\n",
        "                predicted_index = torch.argmax(attention_score).item()\n",
        "\n",
        "                # Compute loss\n",
        "                target_tensor = torch.tensor([target_index], dtype=torch.long).to(device)\n",
        "                loss = criterion(attention_score.unsqueeze(0), target_tensor)  # unsqueeze to match shape: (1, num_keys)\n",
        "                losses.append(loss)\n",
        "\n",
        "                # Backprop & optimize\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Accuracy tracking\n",
        "                if predicted_index == target_index:\n",
        "                    correct_pred += 1\n",
        "                total_sample += 1\n",
        "\n",
        "        end_time = time.time()\n",
        "        epoch_time = end_time - start_time\n",
        "        epoch_times.append(epoch_time)\n",
        "        # Compute each epoch accuracy, loss & stack for loss plot\n",
        "        epoch_loss = torch.stack(losses).mean().item()\n",
        "        epoch_accuracy = correct_pred / total_sample\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy*100:.2f}%, Runtime: {epoch_time:.2f} seconds\")\n",
        "        epoch_losses.append(epoch_loss)\n",
        "        epoch_accuracies.append(epoch_accuracy)\n",
        "\n",
        "    print(f\"Average Accuracy over {num_epochs} Epochs: {sum(epoch_accuracies)/len(epoch_accuracies)*100:.2f}%\")\n",
        "    print(f\"Average runtime over {num_epochs} Epochs: {sum(epoch_times)/len(epoch_times):.2f}s\")\n",
        "\n",
        "    # Loss plot\n",
        "    plt.figure()\n",
        "    plt.clf()\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(f\"Training Loss over {num_epochs} Epochs\")\n",
        "    plt.plot(epoch_losses)\n",
        "    plt.grid()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "id": "fZ6ZfR_moy59",
        "outputId": "13830a93-8747-48e1-ea4c-b4bf6f85cb13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15 Loss: 1.6432, Accuracy: 55.10%, Runtime: 43.74 seconds\n",
            "Epoch 2/15 Loss: 1.4704, Accuracy: 93.27%, Runtime: 43.20 seconds\n",
            "Epoch 3/15 Loss: 1.2783, Accuracy: 94.78%, Runtime: 44.01 seconds\n",
            "Epoch 4/15 Loss: 1.1771, Accuracy: 96.06%, Runtime: 41.85 seconds\n",
            "Epoch 5/15 Loss: 1.1051, Accuracy: 97.45%, Runtime: 43.18 seconds\n",
            "Epoch 6/15 Loss: 1.0706, Accuracy: 98.26%, Runtime: 43.93 seconds\n",
            "Epoch 7/15 Loss: 1.0561, Accuracy: 96.98%, Runtime: 43.00 seconds\n",
            "Epoch 8/15 Loss: 1.0357, Accuracy: 97.33%, Runtime: 42.68 seconds\n",
            "Epoch 9/15 Loss: 1.0262, Accuracy: 97.33%, Runtime: 45.41 seconds\n",
            "Epoch 10/15 Loss: 1.0240, Accuracy: 98.38%, Runtime: 42.20 seconds\n",
            "Epoch 11/15 Loss: 1.0043, Accuracy: 98.38%, Runtime: 42.19 seconds\n",
            "Epoch 12/15 Loss: 1.0068, Accuracy: 97.91%, Runtime: 48.48 seconds\n",
            "Epoch 13/15 Loss: 0.9934, Accuracy: 97.80%, Runtime: 43.61 seconds\n",
            "Epoch 14/15 Loss: 0.9923, Accuracy: 97.56%, Runtime: 44.73 seconds\n",
            "Epoch 15/15 Loss: 0.9936, Accuracy: 98.38%, Runtime: 43.50 seconds\n",
            "Average Accuracy over 15 Epochs: 94.33%\n",
            "Average runtime over 15 Epochs: 43.71s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_KVMemNet(model, optimizer, criterion, train_data, num_epochs, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ecGNHCNhTGxK"
      },
      "outputs": [],
      "source": [
        "# Testing\n",
        "def test_KVMemNet(model, test_data, device):\n",
        "    model.eval()\n",
        "\n",
        "    correct_pred = 0\n",
        "    total_sample = 0\n",
        "    random.seed(100)\n",
        "\n",
        "    for people_index in range(len(test_data)):\n",
        "        batch_data = test_data[people_index]\n",
        "\n",
        "        # Add random data\n",
        "        random_person_1 = test_data[random.randint(0, len(test_data)-1)]\n",
        "        random_person_2 = test_data[random.randint(0, len(test_data)-1)]\n",
        "        concatenate = batch_data + random_person_1 + random_person_2\n",
        "        #concatenate = batch_data\n",
        "\n",
        "        keys = [multihot(item[1], reduced_VOCAB) for item in concatenate]\n",
        "        values = [multihot(item[2], reduced_VOCAB) for item in concatenate]\n",
        "\n",
        "        keys = torch.stack([torch.tensor(k, dtype=torch.float32) for k in keys]).unsqueeze(0).to(device)\n",
        "        values = torch.stack([torch.tensor(v, dtype=torch.float32) for v in values]).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            y_embed = model.embedding_B(values.clone()).squeeze(0)\n",
        "\n",
        "            for relation_index in range(len(batch_data)):\n",
        "                question = keys[0][relation_index].unsqueeze(0).to(device)\n",
        "\n",
        "                output = model(question, keys, values).squeeze(0)\n",
        "                attention_score = torch.nn.functional.softmax(torch.inner(y_embed, output), dim=0)\n",
        "\n",
        "                target_index = relation_index\n",
        "                predicted_index = torch.argmax(attention_score).item()\n",
        "\n",
        "                # Accuracy tracking\n",
        "                if predicted_index == target_index:\n",
        "                    correct_pred += 1\n",
        "                total_sample += 1\n",
        "\n",
        "    # Test Accuracy\n",
        "    accuracy = correct_pred / total_sample\n",
        "    print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "    return accuracy*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfdFeh8EE-OU",
        "outputId": "2c4d4f15-41e8-44fe-8f73-c3e7a84ea795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 73.37%\n"
          ]
        }
      ],
      "source": [
        "acc_multihot = test_KVMemNet(model, test_data, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "DpPk82WT4u8v"
      },
      "outputs": [],
      "source": [
        "# Save trained model to Google Drive\n",
        "# https://docs.pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/NLP/KVMemNet.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRCn-LZmMNCp"
      },
      "source": [
        "# Step 5: Evaluate Model Results with QA Function - Multihot\n",
        "\n",
        "Given a natural language question:\n",
        "1. Convert the question into a bag-of-words vector using the shared vocabulary.\n",
        "2. Select a set of relevant (key, value) memory pairs from the database to serve as context.\n",
        "3. Feed the question and the memory pairs into the trained KVMemNet model.\n",
        "4. Obtain an output vector from the model and use it to compute attention scores over the values.\n",
        "5. Select the value with the highest attention score.\n",
        "6. Return the original string form of that value as the model’s answer.\n",
        "This final output should match the natural language answer to the question.\n",
        "\n",
        "**Note** The natural language answer returned by the QA function includes the person's name, which is also present in the original question. This is a result of the way the input dataset was constructed.\n",
        "\n",
        "Because of this structure, evaluating the model’s output is straightforward:\n",
        "- If the name in the model's answer does not match the name in the question, the answer is **definitively incorrect**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo9Wfvzd595Z",
        "outputId": "e6764a7f-1dab-41fa-ce5e-436a14298fd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Load trained model from Google Drive\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/NLP/KVMemNet.pth\", map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dylo1eEHbY_a"
      },
      "outputs": [],
      "source": [
        "# Create the Question-Answer (QA) function\n",
        "def QA(model, question_text, keys, values, concatanate, device):\n",
        "    model.eval()\n",
        "\n",
        "    question = multihot(question_text, reduced_VOCAB)\n",
        "    question_tensor = torch.tensor(question, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    keys_tensor = torch.stack([torch.tensor(k, dtype=torch.float32) for k in keys]).unsqueeze(0).to(device)\n",
        "    values_tensor = torch.stack([torch.tensor(v, dtype=torch.float32) for v in values]).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        y_embed = model.embedding_B(values_tensor).squeeze(0)\n",
        "        output = model(question_tensor, keys_tensor, values_tensor).squeeze(0)\n",
        "\n",
        "        attention_score = torch.nn.functional.softmax(torch.inner(y_embed, output), dim=0)\n",
        "        predicted_index = torch.argmax(attention_score).item()\n",
        "        return concatanate[predicted_index][2]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Analyses**: Following are 3 correct results (**Ex1**, **Ex3**, **Ex5** ) and 3 incorrect results (**EX2**, **Ex4**, **Ex6**)."
      ],
      "metadata": {
        "id": "drANg1RE_7L6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TioK9dtb-HP5",
        "outputId": "38f11eef-c292-49e7-de9a-4f7b9240c287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The question               : What was mara thompson's birth date?\n",
            "The answer from the model  : mara thompson 4 october 1961\n",
            "The ground-truth answer    : 4 october 1961\n",
            "\n",
            "The model output is Correct!\n"
          ]
        }
      ],
      "source": [
        "#----------------------------------------\n",
        "# Ex1: QA function with correct output\n",
        "#----------------------------------------\n",
        "question_text = \"What was mara thompson's birth date?\"\n",
        "ground_truth = DB['mara thompson']['birth_date']\n",
        "concatenate = trimmed_DB[name_to_index['mara thompson']] + trimmed_DB[name_to_index['betty montgomery']] + trimmed_DB[name_to_index['william hague']]\n",
        "\n",
        "keys = [multihot(item[1], reduced_VOCAB) for item in concatenate]\n",
        "values = [multihot(item[2], reduced_VOCAB) for item in concatenate]\n",
        "\n",
        "print(f\"The question               : {question_text}\")\n",
        "answer = QA(model, question_text, keys, values, concatenate, device)\n",
        "print(f\"The answer from the model  : {answer}\")\n",
        "\n",
        "# Double-check the correct answer in DB\n",
        "print(f\"The ground-truth answer    : {ground_truth}\")\n",
        "\n",
        "res = 'Correct' if ground_truth in answer else 'Incorrect'\n",
        "print()\n",
        "print(f\"The model output is {res}!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-24dHfNumQJS",
        "outputId": "76ffbd11-e6cd-4fa9-ead7-87754c45c5a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The question               : What was heinrich albertz's death date?\n",
            "The answer from the model  : heinrich albert 1 november 1960\n",
            "The ground-truth answer    : 18 may 1993\n",
            "\n",
            "The model output is Incorrect!\n"
          ]
        }
      ],
      "source": [
        "#----------------------------------------\n",
        "# Ex2: QA function with incorrect output\n",
        "#----------------------------------------\n",
        "question_text = \"What was heinrich albertz's death date?\"\n",
        "ground_truth = DB['heinrich albertz']['death_date']\n",
        "concatenate = trimmed_DB[name_to_index['harry holgate']] + trimmed_DB[name_to_index['heinrich albert']] + trimmed_DB[name_to_index['heinrich albertz']]\n",
        "\n",
        "keys = [multihot(item[1], reduced_VOCAB) for item in concatenate]\n",
        "values = [multihot(item[2], reduced_VOCAB) for item in concatenate]\n",
        "\n",
        "print(f\"The question               : {question_text}\")\n",
        "answer = QA(model, question_text, keys, values, concatenate, device)\n",
        "print(f\"The answer from the model  : {answer}\")\n",
        "\n",
        "# Double-check the correct answer in DB\n",
        "print(f\"The ground-truth answer    : {ground_truth}\")\n",
        "\n",
        "res = 'Correct' if ground_truth in answer else 'Incorrect'\n",
        "print()\n",
        "print(f\"The model output is {res}!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qNTavFivdGm"
      },
      "source": [
        "**Ex1**: The plausible candidates for the question have **distinct names**, and the question contains the keyword ***birth date*** for the target key-value pair. These factors help the model yield the correct result.\n",
        "\n",
        "**Ex2**: It has two **similar names**. Even though the question also includes the keyword ***death date***, the high similarity between **\"heinrich albert\"** and **\"heinrich albertz\"** confuses the model and hence leads to the incorrect answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4LlpLuCoKr5",
        "outputId": "9cd1e78d-9a73-4061-f0dd-41b8064239a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The question               : What was jon tester's birth date?\n",
            "The answer from the model  : jon tester 21 august 1956\n",
            "The ground-truth answer    : 21 august 1956\n",
            "\n",
            "The model output is Correct!\n"
          ]
        }
      ],
      "source": [
        "#----------------------------------------\n",
        "# Ex3: QA function with correct output\n",
        "#----------------------------------------\n",
        "\n",
        "question_text = \"What was jon tester's birth date?\"\n",
        "ground_truth = DB['jon tester']['birth_date']\n",
        "concatenate = trimmed_DB[name_to_index['jon tester']] + trimmed_DB[name_to_index['ana botella']] + trimmed_DB[name_to_index['james seddon']]\n",
        "\n",
        "keys = [multihot(item[1], reduced_VOCAB) for item in concatenate]\n",
        "values = [multihot(item[2], reduced_VOCAB) for item in concatenate]\n",
        "\n",
        "print(f\"The question               : {question_text}\")\n",
        "answer = QA(model, question_text, keys, values, concatenate, device)\n",
        "print(f\"The answer from the model  : {answer}\")\n",
        "\n",
        "# Double-check the correct answer in DB\n",
        "print(f\"The ground-truth answer    : {ground_truth}\")\n",
        "\n",
        "res = 'Correct' if ground_truth in answer else 'Incorrect'\n",
        "print()\n",
        "print(f\"The model output is {res}!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNYEEWmly3MS",
        "outputId": "894f6eb3-9371-4076-e27f-22cba0a7313d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The question               : When was jon tester born?\n",
            "The answer from the model  : jon tester congregationalism\n",
            "The ground-truth answer    : 21 august 1956\n",
            "\n",
            "The model output is Incorrect!\n"
          ]
        }
      ],
      "source": [
        "#----------------------------------------\n",
        "# Ex4: QA function with incorrect output\n",
        "#----------------------------------------\n",
        "\n",
        "question_text = \"When was jon tester born?\"\n",
        "ground_truth = DB['jon tester']['birth_date']\n",
        "concatenate = trimmed_DB[name_to_index['jon tester']] + trimmed_DB[name_to_index['ana botella']] + trimmed_DB[name_to_index['james seddon']]\n",
        "\n",
        "keys = [multihot(item[1], reduced_VOCAB) for item in concatenate]\n",
        "values = [multihot(item[2], reduced_VOCAB) for item in concatenate]\n",
        "\n",
        "print(f\"The question               : {question_text}\")\n",
        "answer = QA(model, question_text, keys, values, concatenate, device)\n",
        "print(f\"The answer from the model  : {answer}\")\n",
        "\n",
        "# Double-check the correct answer in DB\n",
        "print(f\"The ground-truth answer    : {ground_truth}\")\n",
        "\n",
        "res = 'Correct' if ground_truth in answer else 'Incorrect'\n",
        "print()\n",
        "print(f\"The model output is {res}!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ex3** and **Ex4**: They use the same candidates and similar questions, but different phrasings.\n",
        "\n",
        "**Ex3** uses the keyword ***birth date*** and yields the correct result.\n",
        "\n",
        "**Ex4** uses ***born*** instead of ***birth date***, which is natural in real-world question-answering scenarios. However, the model lacks semantic understanding and cannot associate ***birth date*** and ***born*** as related terms. As a result, it outputs the incorrect answer."
      ],
      "metadata": {
        "id": "PDwuZPG-AlzD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSqTZ0RoyXvX",
        "outputId": "2b08add2-16af-4b3b-a22d-7ea36b6a10c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The question               : What was jon tester's religion?\n",
            "The answer from the model  : jon tester congregationalism\n",
            "The ground-truth answer    : congregationalism\n",
            "\n",
            "The model output is Correct!\n"
          ]
        }
      ],
      "source": [
        "#----------------------------------------\n",
        "# Ex5: QA function with correct output\n",
        "#----------------------------------------\n",
        "\n",
        "question_text = \"What was jon tester's religion?\"\n",
        "ground_truth = DB['jon tester']['religion']\n",
        "concatenate = trimmed_DB[name_to_index['jon tester']] + trimmed_DB[name_to_index['ana botella']] + trimmed_DB[name_to_index['james seddon']]\n",
        "\n",
        "keys = [multihot(item[1], reduced_VOCAB) for item in concatenate]\n",
        "values = [multihot(item[2], reduced_VOCAB) for item in concatenate]\n",
        "\n",
        "print(f\"The question               : {question_text}\")\n",
        "answer = QA(model, question_text, keys, values, concatenate, device)\n",
        "print(f\"The answer from the model  : {answer}\")\n",
        "\n",
        "# Double-check the correct answer in DB\n",
        "print(f\"The ground-truth answer    : {ground_truth}\")\n",
        "\n",
        "res = 'Correct' if ground_truth in answer else 'Incorrect'\n",
        "print()\n",
        "print(f\"The model output is {res}!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDpvjkyzqUIP",
        "outputId": "59c87446-c547-42de-a293-c7a60bdc2303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The question               : What was manser marmion's religion?\n",
            "The answer from the model  : ana botella roman catholic\n",
            "The ground-truth answer    : Not exist\n",
            "\n",
            "The model output is Incorrect!\n"
          ]
        }
      ],
      "source": [
        "#----------------------------------------\n",
        "# Ex6: QA function with incorrect output\n",
        "#----------------------------------------\n",
        "\n",
        "question_text = \"What was manser marmion's religion?\"\n",
        "if 'religion' in DB['manser marmion']:\n",
        "    ground_truth = DB['manser marmion']['religion']\n",
        "else:\n",
        "    ground_truth = 'Not exist'\n",
        "concatenate = trimmed_DB[name_to_index['jon tester']] + trimmed_DB[name_to_index['ana botella']] + trimmed_DB[name_to_index['manser marmion']]\n",
        "\n",
        "keys = [multihot(item[1], reduced_VOCAB) for item in concatenate]\n",
        "values = [multihot(item[2], reduced_VOCAB) for item in concatenate]\n",
        "\n",
        "print(f\"The question               : {question_text}\")\n",
        "answer = QA(model, question_text, keys, values, concatenate, device)\n",
        "print(f\"The answer from the model  : {answer}\")\n",
        "\n",
        "# Double-check the correct answer in DB\n",
        "print(f\"The ground-truth answer    : {ground_truth}\")\n",
        "\n",
        "res = 'Correct' if ground_truth in answer else 'Incorrect'\n",
        "print()\n",
        "print(f\"The model output is {res}!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ex5** and **Ex6**: Their questions use the same keyword ***religion***, but the candidate contents are slightly different.\n",
        "\n",
        "**Ex5** has valid values for the keyword across all candidates.\n",
        "\n",
        "**Ex6** has one candidate (which is also the queried entity) that lacks a key-value pair for the keyword. Since the model has no mechanism to handle missing data, it returns an incorrect answer."
      ],
      "metadata": {
        "id": "8gn7L2J4ApD1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: GloVe Embedding\n",
        "\n",
        "GloVe embeddings (also referred to as **embeddings** in the remainder of this project) assign a unique vector representation to each word based on its co-occurrence statistics in a large corpus. Words that appear in similar contexts will have similar embeddings, capturing semantic similarity. This step investigates whether these semantic relationships can help the model improve its performance and solve the incorrect cases **Ex2** and **Ex4** in Step 4 more effectively."
      ],
      "metadata": {
        "id": "EXhF9thYD8-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgIANC4TR6VZ",
        "outputId": "67bc2b5a-3caf-4672-9594-6bf8ffb79f7f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-10 22:40:24--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2025-08-10 22:40:24--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2025-08-10 22:40:24--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  3.31MB/s    in 2m 41s  \n",
            "\n",
            "2025-08-10 22:43:06 (5.09 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_glove_embeddings(glove_path):\n",
        "    glove = {}\n",
        "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            word = parts[0]\n",
        "            vector = torch.tensor([float(x) for x in parts[1:]], dtype=torch.float32)\n",
        "            glove[word] = vector\n",
        "    return glove"
      ],
      "metadata": {
        "id": "4Jm6OQ1dHiB5"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embedding_matrix(vocab, glove, embed_dim):\n",
        "    matrix = torch.randn(vocab.num_words(), embed_dim)  # Random init\n",
        "    for word in vocab.get_words():\n",
        "        idx = vocab.word2index(word)\n",
        "        if word in glove:\n",
        "            matrix[idx] = glove[word]\n",
        "    return matrix"
      ],
      "metadata": {
        "id": "tkQ9QjJkHmNq"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The similarity between ***birth*** and ***born*** is 0.5217, which indicates a moderate semantic similarity."
      ],
      "metadata": {
        "id": "Rx6vPDG5hhhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_path = \"glove.6B.100d.txt\"\n",
        "glove_dict = load_glove_embeddings(glove_path)\n",
        "word1, word2 = 'birth', 'born'\n",
        "vec1, vec2 = glove_dict[word1], glove_dict[word2]\n",
        "\n",
        "sim = F.cosine_similarity(vec1.unsqueeze(0), vec2.unsqueeze(0)).item()\n",
        "print(f\"Similarity ({word1} vs {word2}): {sim:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wT4kvRcF279",
        "outputId": "67831156-89bd-462e-ce10-eb5757d022a2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity (birth vs born): 0.5217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modify Key-Value Memory Network for GloVe"
      ],
      "metadata": {
        "id": "Bh0dxSs4eTFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "KVMemNet_Embedding model is defined in private_models.PrivateModels for this project.\n",
        "The implementation is hidden for academic integrity.\n",
        "'''\n",
        "KVMemNet_Embedding = PrivateModels.KVMemNet_Embedding"
      ],
      "metadata": {
        "id": "PUxF4rLG8Z6Q"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Key-Value Memory Network\n",
        "glove_path = \"glove.6B.100d.txt\"\n",
        "freeze_embeddings = False  # fine-tune GloVe\n",
        "vocab_size = reduced_VOCAB.num_words()\n",
        "embed_size = 100\n",
        "learning_rate = 0.01\n",
        "num_epochs = 15\n",
        "\n",
        "# Load GloVe\n",
        "glove_dict = load_glove_embeddings(glove_path)\n",
        "\n",
        "# Create embedding matrix\n",
        "embedding_matrix = create_embedding_matrix(reduced_VOCAB, glove_dict, embed_size)\n",
        "\n",
        "model_embed = KVMemNet_Embedding(vocab_size=vocab_size, embed_dim=embed_size, embedding_matrix=embedding_matrix, freeze=freeze_embeddings).to(device)\n",
        "optimizer_embed = optim.Adam(model_embed.parameters(), lr=learning_rate)\n",
        "criterion_embed = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "238KhKA0Edj5"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "def train_KVMemNet_Embedding(model_embed, optimizer_embed, criterion_embed, train_data, num_epochs, device):\n",
        "    model_embed.train()\n",
        "\n",
        "    epoch_losses = []\n",
        "    epoch_accuracies = []\n",
        "    epoch_times = []\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "        losses = []\n",
        "        correct_pred = 0\n",
        "        total_sample = 0\n",
        "        random.seed(epoch)\n",
        "\n",
        "        for people_index in range(len(train_data)):\n",
        "            batch_data = train_data[people_index]\n",
        "\n",
        "            # Add random data\n",
        "            random_person_1 = train_data[random.randint(0, len(train_data) - 1)]\n",
        "            random_person_2 = train_data[random.randint(0, len(train_data) - 1)]\n",
        "            concatenate = batch_data + random_person_1 + random_person_2\n",
        "\n",
        "            # Convert words to index tensors for keys/values\n",
        "            keys = [torch.tensor([reduced_VOCAB.word2index(w) for w in item[1]], dtype=torch.long) for item in concatenate]\n",
        "            values = [torch.tensor([reduced_VOCAB.word2index(w) for w in item[2]], dtype=torch.long) for item in concatenate]\n",
        "\n",
        "            # Pad sequences to same length, result shape: [1, N, max_len]\n",
        "            keys = pad_sequence(keys, batch_first=True).unsqueeze(0).to(device)\n",
        "            values = pad_sequence(values, batch_first=True).unsqueeze(0).to(device)\n",
        "\n",
        "            y_embed = model_embed.embedding_B(values.clone()).mean(dim=2).squeeze(0).detach()\n",
        "\n",
        "            for relation_index in range(len(batch_data)):\n",
        "                question = torch.tensor([reduced_VOCAB.word2index(w) for w in batch_data[relation_index][1]], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "                output = model_embed(question, keys, values).squeeze(0)\n",
        "                attention_score = torch.nn.functional.softmax(torch.inner(y_embed, output), dim=0)\n",
        "\n",
        "                target_index = relation_index\n",
        "                predicted_index = torch.argmax(attention_score).item()\n",
        "\n",
        "                # Compute loss\n",
        "                target_tensor = torch.tensor([target_index], dtype=torch.long).to(device)\n",
        "                loss = criterion_embed(attention_score.unsqueeze(0), target_tensor)\n",
        "                losses.append(loss)\n",
        "\n",
        "                # Backprop & optimize\n",
        "                optimizer_embed.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer_embed.step()\n",
        "\n",
        "                # Accuracy tracking\n",
        "                if predicted_index == target_index:\n",
        "                    correct_pred += 1\n",
        "                total_sample += 1\n",
        "\n",
        "        end_time = time.time()\n",
        "        epoch_time = end_time - start_time\n",
        "        epoch_times.append(epoch_time)\n",
        "        # Compute each epoch accuracy, loss & stack for loss plot\n",
        "        epoch_loss = torch.stack(losses).mean().item()\n",
        "        epoch_accuracy = correct_pred / total_sample\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy*100:.2f}%, Runtime: {epoch_time:.2f} seconds\")\n",
        "        epoch_losses.append(epoch_loss)\n",
        "        epoch_accuracies.append(epoch_accuracy)\n",
        "\n",
        "    print(f\"Average Accuracy over {num_epochs} Epochs: {sum(epoch_accuracies)/len(epoch_accuracies)*100:.2f}%\")\n",
        "    print(f\"Average runtime over {num_epochs} Epochs: {sum(epoch_times)/len(epoch_times):.2f}s\")\n",
        "\n",
        "    # Loss plot\n",
        "    plt.figure()\n",
        "    plt.clf()\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(f\"Training Loss over {num_epochs} Epochs\")\n",
        "    plt.plot(epoch_losses)\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4uUF1cgpTtZP"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_KVMemNet_Embedding(model_embed, optimizer_embed, criterion_embed, train_data, num_epochs, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "id": "322yShC_D_vI",
        "outputId": "e5312a21-a27a-4685-e674-7c118a21c6d6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15 Loss: 1.5822, Accuracy: 36.77%, Runtime: 52.16 seconds\n",
            "Epoch 2/15 Loss: 1.3970, Accuracy: 61.25%, Runtime: 53.10 seconds\n",
            "Epoch 3/15 Loss: 1.2746, Accuracy: 72.74%, Runtime: 51.84 seconds\n",
            "Epoch 4/15 Loss: 1.1910, Accuracy: 79.93%, Runtime: 49.84 seconds\n",
            "Epoch 5/15 Loss: 1.1342, Accuracy: 85.61%, Runtime: 50.03 seconds\n",
            "Epoch 6/15 Loss: 1.1034, Accuracy: 88.05%, Runtime: 52.14 seconds\n",
            "Epoch 7/15 Loss: 1.0919, Accuracy: 88.75%, Runtime: 51.62 seconds\n",
            "Epoch 8/15 Loss: 1.0812, Accuracy: 89.91%, Runtime: 52.09 seconds\n",
            "Epoch 9/15 Loss: 1.0525, Accuracy: 92.46%, Runtime: 49.95 seconds\n",
            "Epoch 10/15 Loss: 1.0672, Accuracy: 92.34%, Runtime: 50.81 seconds\n",
            "Epoch 11/15 Loss: 1.0541, Accuracy: 92.11%, Runtime: 52.04 seconds\n",
            "Epoch 12/15 Loss: 1.0396, Accuracy: 94.08%, Runtime: 49.92 seconds\n",
            "Epoch 13/15 Loss: 1.0247, Accuracy: 94.66%, Runtime: 51.01 seconds\n",
            "Epoch 14/15 Loss: 1.0247, Accuracy: 94.32%, Runtime: 54.90 seconds\n",
            "Epoch 15/15 Loss: 1.0231, Accuracy: 95.94%, Runtime: 55.88 seconds\n",
            "Average Accuracy over 15 Epochs: 83.93%\n",
            "Average runtime over 15 Epochs: 51.82s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "def test_KVMemNet_Embedding(model_embed, test_data, device):\n",
        "    model_embed.eval()\n",
        "\n",
        "    correct_pred = 0\n",
        "    total_sample = 0\n",
        "    random.seed(100)\n",
        "\n",
        "    for people_index in range(len(test_data)):\n",
        "        batch_data = test_data[people_index]\n",
        "\n",
        "        # Add random data\n",
        "        random_person_1 = test_data[random.randint(0, len(test_data) - 1)]\n",
        "        random_person_2 = test_data[random.randint(0, len(test_data) - 1)]\n",
        "        concatenate = batch_data + random_person_1 + random_person_2\n",
        "\n",
        "        # Convert words to index tensors for keys/values\n",
        "        keys = [torch.tensor([reduced_VOCAB.word2index(w) for w in item[1]], dtype=torch.long) for item in concatenate]\n",
        "        values = [torch.tensor([reduced_VOCAB.word2index(w) for w in item[2]], dtype=torch.long) for item in concatenate]\n",
        "\n",
        "        # Pad sequences to same length, result shape: [1, N, max_len]\n",
        "        keys = pad_sequence(keys, batch_first=True).unsqueeze(0).to(device)\n",
        "        values = pad_sequence(values, batch_first=True).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            y_embed = model_embed.embedding_B(values.clone()).mean(dim=2).squeeze(0).detach()\n",
        "\n",
        "            for relation_index in range(len(batch_data)):\n",
        "                question = torch.tensor([reduced_VOCAB.word2index(w) for w in batch_data[relation_index][1]], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "                output = model_embed(question, keys, values).squeeze(0)\n",
        "                attention_score = torch.nn.functional.softmax(torch.inner(y_embed, output), dim=0)\n",
        "\n",
        "                target_index = relation_index\n",
        "                predicted_index = torch.argmax(attention_score).item()\n",
        "\n",
        "                # Accuracy tracking\n",
        "                if predicted_index == target_index:\n",
        "                    correct_pred += 1\n",
        "                total_sample += 1\n",
        "\n",
        "    # Test Accuracy\n",
        "    accuracy = correct_pred / total_sample\n",
        "    print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "    return accuracy*100"
      ],
      "metadata": {
        "id": "Qgsoq1OXuQ_y"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_embedding = test_KVMemNet_Embedding(model_embed, test_data, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upchnnCdwJvi",
        "outputId": "28af38b9-592d-4bf8-e586-8a45020f2172"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 93.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save trained model_embed to Google Drive\n",
        "# https://docs.pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html\n",
        "torch.save(model_embed.state_dict(), \"/content/drive/MyDrive/NLP/KVMemNet_embed.pth\")"
      ],
      "metadata": {
        "id": "t0g4Jd7zcv6j"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Evaluate Model Results with QA Function - Embedding\n",
        "\n",
        "This step runs the training loop for the embedding-based model, following the same structure as **Step 5** but replacing the multihot representation with GloVe embeddings."
      ],
      "metadata": {
        "id": "0F6e2IDNMNVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained model_embed from Google Drive\n",
        "model_embed.load_state_dict(torch.load(\"/content/drive/MyDrive/NLP/KVMemNet_embed.pth\", map_location=device))"
      ],
      "metadata": {
        "id": "9yBbTF2Ocy5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504c39ab-1f6a-420f-9819-2b7559f6d41e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Question–Answer (QA) function — for Embedding (GloVe)\n",
        "def clean_question(q):\n",
        "    # Lowercase\n",
        "    q = q.lower()\n",
        "    # Replace possessives (e.g., \"mara thompson's\" → \"mara thompson\")\n",
        "    q = re.sub(r\"'s\\b\", \"\", q)\n",
        "    # Remove punctuation\n",
        "    q = re.sub(r\"[^a-z0-9\\s]\", \"\", q)\n",
        "    # Tokenize\n",
        "    return q.strip().split()\n",
        "\n",
        "def QA_Embedding(model_embed, question_text, concatenated, device):\n",
        "    model_embed.eval()\n",
        "\n",
        "    # Tokenize question if needed\n",
        "    if isinstance(question_text, str):\n",
        "        #question_text = question_text.lower().split()\n",
        "        question_text = clean_question(question_text)\n",
        "\n",
        "    # Convert question to indices\n",
        "    question_indices = [reduced_VOCAB.word2index(w) for w in question_text]\n",
        "    question_tensor = torch.tensor(question_indices, dtype=torch.long).unsqueeze(0).to(device)  # [1, q_len]\n",
        "\n",
        "    # Extract keys and values from concatenated\n",
        "    keys = [item[1] for item in concatenated]\n",
        "    values = [item[2] for item in concatenated]\n",
        "\n",
        "    keys_indices = [torch.tensor([reduced_VOCAB.word2index(w) for w in k], dtype=torch.long) for k in keys]\n",
        "    values_indices = [torch.tensor([reduced_VOCAB.word2index(w) for w in v], dtype=torch.long) for v in values]\n",
        "\n",
        "    keys_tensor = pad_sequence(keys_indices, batch_first=True).unsqueeze(0).to(device)     # [1, N, max_len]\n",
        "    values_tensor = pad_sequence(values_indices, batch_first=True).unsqueeze(0).to(device) # [1, N, max_len]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Compute average value embeddings\n",
        "        y_embed = model_embed.embedding_B(values_tensor.clone()).mean(dim=2).squeeze(0)  # [N, embed_dim]\n",
        "\n",
        "        # Compute model output vector\n",
        "        output = model_embed(question_tensor, keys_tensor, values_tensor).squeeze(0)  # [embed_dim]\n",
        "\n",
        "        # Compute attention and select answer\n",
        "        attention_score = torch.nn.functional.softmax(torch.inner(y_embed, output), dim=0)\n",
        "        predicted_index = torch.argmax(attention_score).item()\n",
        "\n",
        "    return concatenated[predicted_index][2]"
      ],
      "metadata": {
        "id": "WEVvGlNbw0qn"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Analyses**: Evaluate embedding on cases of **Ex1** to **Ex4** in **Step 4**, which correspond to **Ex7** to **Ex10** in this section.\n",
        "\n",
        "For example, **Ex7** evaluates the embedding method using the same question and key–value pairs as in **Ex1**.\n",
        "\n",
        "**Ex8** does the same for **Ex2**, and so on for the remaining examples."
      ],
      "metadata": {
        "id": "o878R-EPHfZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------\n",
        "# Ex7: QA function with correct output (Embedding)\n",
        "#--------------------------------------------\n",
        "question_text = \"What was mara thompson's birth date?\"\n",
        "ground_truth = DB['mara thompson']['birth_date']\n",
        "concatenate = trimmed_DB[name_to_index['mara thompson']] + trimmed_DB[name_to_index['betty montgomery']] + trimmed_DB[name_to_index['william hague']]\n",
        "\n",
        "# Convert keys and values into list of word index sequences\n",
        "keys = [item[1] for item in concatenate]      # list of word lists (key sentences)\n",
        "values = [item[2] for item in concatenate]    # list of word lists (value sentences)\n",
        "\n",
        "# Print question\n",
        "print(f\"The question             : {question_text}\")\n",
        "\n",
        "# Run QA model\n",
        "answer = QA_Embedding(model_embed, question_text, concatenate, device)\n",
        "print(f\"The answer from the model: {answer}\")\n",
        "\n",
        "# Ground truth\n",
        "print(f\"The ground-truth answer  : {ground_truth}\")\n",
        "\n",
        "# Accuracy check\n",
        "res = 'Correct' if ground_truth in answer else 'Incorrect'\n",
        "print()\n",
        "print(f\"The model output is {res}!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inZbpCZHwmsg",
        "outputId": "1d66531a-7492-48b8-b4b1-a38ba86cb9db"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The question             : What was mara thompson's birth date?\n",
            "The answer from the model: mara thompson 4 october 1961\n",
            "The ground-truth answer  : 4 october 1961\n",
            "\n",
            "The model output is Correct!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------\n",
        "# Ex8: QA function with incorrect output (Embedding)\n",
        "#--------------------------------------------\n",
        "question_text =  \"What was heinrich albertz's death date?\"\n",
        "ground_truth = DB['heinrich albertz']['death_date']\n",
        "concatenate = trimmed_DB[name_to_index['harry holgate']] + trimmed_DB[name_to_index['heinrich albert']] + trimmed_DB[name_to_index['heinrich albertz']]\n",
        "\n",
        "# Convert keys and values to list of word index sequences\n",
        "keys = [item[1] for item in concatenate]\n",
        "values = [item[2] for item in concatenate]\n",
        "\n",
        "# Print question\n",
        "print(f\"The question             : {question_text}\")\n",
        "\n",
        "# Run QA model\n",
        "answer = QA_Embedding(model_embed, question_text, concatenate, device)\n",
        "print(f\"The answer from the model: {answer}\")\n",
        "\n",
        "# Ground truth\n",
        "print(f\"The ground-truth answer  : {ground_truth}\")\n",
        "\n",
        "# Accuracy check\n",
        "res = 'Correct' if ground_truth in answer else 'Incorrect'\n",
        "print()\n",
        "print(f\"The model output is {res}!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfKbVyGXxt7J",
        "outputId": "f0bd41a2-9a75-4a73-e2fb-cd29de530e59"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The question             : What was heinrich albertz's death date?\n",
            "The answer from the model: heinrich albert 12 february 1874\n",
            "The ground-truth answer  : 18 may 1993\n",
            "\n",
            "The model output is Incorrect!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For both **Ex7** (corresponding to **Ex1**) and **Ex8** (corresponding to **Ex2**), the embedding method produced identical results to the multihot baseline—correct for **Ex7** and incorrect for **Ex8**. This indicates that, in these cases, using embeddings did not improve model performance or resolve errors caused by name similarity."
      ],
      "metadata": {
        "id": "Yrp3MkBlGcRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#===========================================\n",
        "# Ex9: QA function with correct output (Embedding version)\n",
        "#===========================================\n",
        "question_text = \"What was jon tester's birth date?\"\n",
        "ground_truth = DB['jon tester']['birth_date']\n",
        "concatenate = trimmed_DB[name_to_index['jon tester']] + trimmed_DB[name_to_index['ana botella']] + trimmed_DB[name_to_index['james seddon']]\n",
        "\n",
        "# Convert keys and values to list of word index sequences\n",
        "keys = [item[1] for item in concatenate]\n",
        "values = [item[2] for item in concatenate]\n",
        "\n",
        "# Print question\n",
        "print(f\"The question             : {question_text}\")\n",
        "\n",
        "# Run QA model\n",
        "answer = QA_Embedding(model_embed, question_text, concatenate, device)\n",
        "print(f\"The answer from the model: {answer}\")\n",
        "\n",
        "# Ground truth\n",
        "print(f\"The ground-truth answer  : {ground_truth}\")\n",
        "\n",
        "# Accuracy check\n",
        "res = 'Correct' if ground_truth in answer else 'Incorrect'\n",
        "print()\n",
        "print(f\"The model output is {res}!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbsk1xETymLq",
        "outputId": "305fde5c-ad47-4f70-fb5d-381969209401"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The question             : What was jon tester's birth date?\n",
            "The answer from the model: jon tester 21 august 1956\n",
            "The ground-truth answer  : 21 august 1956\n",
            "\n",
            "The model output is Correct!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#===========================================\n",
        "# Ex10: QA function with correct output (Embedding version)\n",
        "#===========================================\n",
        "question_text = \"When was jon tester born?\"\n",
        "ground_truth = DB['jon tester']['birth_date']\n",
        "concatenate = trimmed_DB[name_to_index['jon tester']] + trimmed_DB[name_to_index['ana botella']] + trimmed_DB[name_to_index['james seddon']]\n",
        "\n",
        "# Convert keys and values to list of word index sequences\n",
        "keys = [item[1] for item in concatenate]\n",
        "values = [item[2] for item in concatenate]\n",
        "\n",
        "# Print question\n",
        "print(f\"The question             : {question_text}\")\n",
        "\n",
        "# Run QA model\n",
        "answer = QA_Embedding(model_embed, question_text, concatenate, device)\n",
        "print(f\"The answer from the model: {answer}\")\n",
        "\n",
        "# Ground truth\n",
        "print(f\"The ground-truth answer  : {ground_truth}\")\n",
        "\n",
        "# Accuracy check\n",
        "res = 'Correct' if ground_truth in answer else 'Incorrect'\n",
        "print()\n",
        "print(f\"The model output is {res}!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fve-pcAky14I",
        "outputId": "1189d89d-e027-48ec-951a-311558946117"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The question             : When was jon tester born?\n",
            "The answer from the model: jon tester 21 august 1956\n",
            "The ground-truth answer  : 21 august 1956\n",
            "\n",
            "The model output is Correct!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For **Ex9** (corresponding to **Ex3**) , the embedding method produced the same correct result as the multihot baseline.\n",
        "\n",
        "For **Ex10** (corresponding to **Ex4**), embeddings improved performance by producing the correct answer where the multihot method had previously failed. This suggests that GloVe embeddings provided useful semantic information that helped the model generalize better in this case, likely because the word vectors capture relationships between terms beyond exact keyword matches."
      ],
      "metadata": {
        "id": "V0zj98gqKITI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Discussion**: Multihot vs. Embedding Performance"
      ],
      "metadata": {
        "id": "_PFs9FS5LO_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(\n",
        "    f\"\"\"\n",
        "    <p style=\"font-size:16px; font-weight:400; line-height:1.35; margin:0.5rem 0;\">\n",
        "      The results indicate a substantial performance gap between the\n",
        "      <strong>multihot baseline</strong> ({acc_multihot:.2f}% test accuracy) and the\n",
        "      <strong>GloVe embedding</strong> method ({acc_embedding:.2f}% test accuracy).\n",
        "    </p>\n",
        "    \"\"\"\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "NbJ_Sl05a2Xe",
        "outputId": "349b3bf1-9f29-42e4-b542-a1fabb7d8741"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <p style=\"font-size:16px; font-weight:400; line-height:1.35; margin:0.5rem 0;\">\n",
              "      The results indicate a substantial performance gap between the\n",
              "      <strong>multihot baseline</strong> (73.37% test accuracy) and the\n",
              "      <strong>GloVe embedding</strong> method (93.49% test accuracy).\n",
              "    </p>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GloVe embeddings** significantly improved accuracy with a moderate increase in training time. The **GloVe embedding model** achieved higher accuracy and stronger generalization. The **multihot baseline** is simpler and faster but less robust to distractors.\n",
        "\n",
        "The multihot representation encodes only the presence or absence of words in a high-dimensional sparse vector. While this approach is simple and computationally inexpensive, it lacks semantic understanding — each word is treated as independent, so it cannot recognize relationships between synonymous or related terms (e.g., ***birth date*** vs. ***born***).\n",
        "\n",
        "This limitation is clearly illustrated in **Ex4** and **Ex10**, where the multihot method failed because the query used ***born*** instead of ***birth date***, even though the underlying fact was the same. In contrast, the embedding model captured the semantic similarity between these terms, producing the correct answer.\n",
        "\n",
        "Similarly, in **name similarity*** cases like **Ex2** and **Ex8**, both methods failed, indicating that while embeddings improve semantic matching, they may still be challenged by near-identical entity names in the candidate set.\n",
        "\n",
        "Overall, embeddings outperform multihot by:"
      ],
      "metadata": {
        "id": "7gOTYt9eMvoQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Capturing semantic relationships between words.\n",
        "2. Reducing sparsity in the input representation.\n",
        "3. Providing a denser, lower-dimensional space for attention scoring."
      ],
      "metadata": {
        "id": "ODpQVmpVNdrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These advantages explain the higher accuracy and the ability to recover correct answers in scenarios where multihot fails."
      ],
      "metadata": {
        "id": "uCbd82DhNkUh"
      }
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}